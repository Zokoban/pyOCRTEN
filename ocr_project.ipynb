{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vSOxAd01zY5-"
      ],
      "authorship_tag": "ABX9TyPy1rYcQPPuwT64tPbzIH5D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zokoban/pyOCRTEN/blob/Full_TensorFlow/ocr_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download all data on the drive "
      ],
      "metadata": {
        "id": "rY2t8iv40Atm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://git.io/J0fjL -O IAM_Words.zip\n",
        "!unzip -qq IAM_Words.zip\n",
        "!\n",
        "!mkdir data\n",
        "!mkdir data/words\n",
        "!tar -xf IAM_Words/words.tgz -C data/words\n",
        "!mv IAM_Words/words.txt data"
      ],
      "metadata": {
        "id": "pQd5d8OitoDO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load all the required packages"
      ],
      "metadata": {
        "id": "TQBEwYLH0FP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "PiYqf_7Uz_YR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load word.txt file"
      ],
      "metadata": {
        "id": "Xiv8jaZB0LZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_txt=pd.read_csv(\"data/words.txt\", \n",
        "                     sep=' ', \n",
        "                     names=[\"word_id\",\"segmentation_result\",\"gray_level\",\"x\",\"y\",\"pxw\",\"pxh\",\"grammatical_tag\",\"transcription_1\",\"transcription_2\",\"transcription_3\"], \n",
        "                     quoting=csv.QUOTE_NONE, \n",
        "                     skiprows=18, \n",
        "                     on_bad_lines=\"warn\")\n",
        "\n",
        "def f(x):\n",
        "    if x == \"nan\":\n",
        "        return \"\"\n",
        "    else:\n",
        "        return x\n",
        "word_txt[\"transcription\"]=word_txt.transcription_1.astype(\"str\")+word_txt.transcription_2.astype(\"str\").apply(f)+word_txt.transcription_3.astype(\"str\").apply(f)\n",
        "word_txt=word_txt.drop(columns=[\"transcription_1\",\"transcription_2\",\"transcription_3\"])\n",
        "\n",
        "def f(x):\n",
        "    return len(x)\n",
        "\n",
        "word_txt[\"number_components\"]=word_txt.transcription.apply(f)\n",
        "\n",
        "print(\"word_txt Length: \",len(word_txt))\n",
        "word_txt.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "mWa3zM2KvL5q",
        "outputId": "52d1f182-c2fd-44ea-9b4f-47133dda4400"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word_txt Length:  115320\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          word_id segmentation_result  gray_level     x    y  pxw  pxh  \\\n",
              "0  a01-000u-00-00                  ok         154   408  768   27   51   \n",
              "1  a01-000u-00-01                  ok         154   507  766  213   48   \n",
              "2  a01-000u-00-02                  ok         154   796  764   70   50   \n",
              "3  a01-000u-00-03                  ok         154   919  757  166   78   \n",
              "4  a01-000u-00-04                  ok         154  1185  754  126   61   \n",
              "\n",
              "  grammatical_tag transcription  number_components  \n",
              "0              AT             A                  1  \n",
              "1              NN          MOVE                  4  \n",
              "2              TO            to                  2  \n",
              "3              VB          stop                  4  \n",
              "4             NPT           Mr.                  3  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f522ac33-fb9e-4d61-81a1-dfeb1a58fd89\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_id</th>\n",
              "      <th>segmentation_result</th>\n",
              "      <th>gray_level</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>pxw</th>\n",
              "      <th>pxh</th>\n",
              "      <th>grammatical_tag</th>\n",
              "      <th>transcription</th>\n",
              "      <th>number_components</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a01-000u-00-00</td>\n",
              "      <td>ok</td>\n",
              "      <td>154</td>\n",
              "      <td>408</td>\n",
              "      <td>768</td>\n",
              "      <td>27</td>\n",
              "      <td>51</td>\n",
              "      <td>AT</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a01-000u-00-01</td>\n",
              "      <td>ok</td>\n",
              "      <td>154</td>\n",
              "      <td>507</td>\n",
              "      <td>766</td>\n",
              "      <td>213</td>\n",
              "      <td>48</td>\n",
              "      <td>NN</td>\n",
              "      <td>MOVE</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a01-000u-00-02</td>\n",
              "      <td>ok</td>\n",
              "      <td>154</td>\n",
              "      <td>796</td>\n",
              "      <td>764</td>\n",
              "      <td>70</td>\n",
              "      <td>50</td>\n",
              "      <td>TO</td>\n",
              "      <td>to</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a01-000u-00-03</td>\n",
              "      <td>ok</td>\n",
              "      <td>154</td>\n",
              "      <td>919</td>\n",
              "      <td>757</td>\n",
              "      <td>166</td>\n",
              "      <td>78</td>\n",
              "      <td>VB</td>\n",
              "      <td>stop</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a01-000u-00-04</td>\n",
              "      <td>ok</td>\n",
              "      <td>154</td>\n",
              "      <td>1185</td>\n",
              "      <td>754</td>\n",
              "      <td>126</td>\n",
              "      <td>61</td>\n",
              "      <td>NPT</td>\n",
              "      <td>Mr.</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f522ac33-fb9e-4d61-81a1-dfeb1a58fd89')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f522ac33-fb9e-4d61-81a1-dfeb1a58fd89 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f522ac33-fb9e-4d61-81a1-dfeb1a58fd89');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Choice of the fraction of the dataset.\n",
        "### Removal of the transcription error.\n",
        "### Removal of the unwanted columns."
      ],
      "metadata": {
        "id": "4teX3LNn3BJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import imghdr\n",
        "\n",
        "data_dir = \"data/words/\"\n",
        "image_extensions = [\".png\"]  # add there all your images file extensions\n",
        "img_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\"]\n",
        "\n",
        "def img_path(word):\n",
        "    path=data_dir+word.split(\"-\")[0]+\"/\"+word.split(\"-\")[0]+\"-\"+word.split(\"-\")[1]+\"/\"+word+\".png\"\n",
        "    \n",
        "    return path\n",
        "\n",
        "def removal_of_corrupt_image(df):\n",
        "  index_to_drop=[]\n",
        "  for filepath in Path(data_dir).rglob(\"*\"):\n",
        "      if filepath.suffix.lower() in image_extensions:\n",
        "          img_type = imghdr.what(filepath)\n",
        "          if img_type is None:\n",
        "              index_to_drop.append(df[df.filepath==str(filepath)].index)\n",
        "              df=df.drop(labels=df[df.filepath==str(filepath)].index)\n",
        "              print(f\"{filepath} is not an image\")\n",
        "          elif img_type not in img_type_accepted_by_tf:\n",
        "              df=df.drop(labels=df[df.filepath==str(filepath)].index)\n",
        "              print(f\"{filepath} is a {img_type}, not accepted by TensorFlow and is drop\")\n",
        "  return df\n",
        "\n",
        "list_columns_to_remove=[\"segmentation_result\",\"gray_level\",\"x\",\"y\",\"pxw\",\"pxh\",\"grammatical_tag\",\"number_components\"]\n",
        "fraction = 0.5\n",
        "df = word_txt[word_txt.segmentation_result == \"ok\"]\\\n",
        "    .drop(columns=list_columns_to_remove)\\\n",
        "    .sample(frac=fraction,random_state=1234)\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "print(\"df Length: \",len(df))\n",
        "df[\"filepath\"]=df.word_id.apply(img_path)\n",
        "df=removal_of_corrupt_image(df)\n",
        "print(\"df Length: \",len(df))\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "EHQ1vKx53Wbj",
        "outputId": "461b0366-58db-405f-bbea-10cb325ceb90"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df Length:  48228\n",
            "data/words/r06/r06-022/r06-022-03-05.png is not an image\n",
            "data/words/a01/a01-117/a01-117-05-02.png is not an image\n",
            "df Length:  48227\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               word_id transcription  \\\n",
              "23187    c02-022-03-01     indignity   \n",
              "38064    d06-107-08-01          with   \n",
              "20965    b06-023-03-03            an   \n",
              "77141   h07-063b-00-00          More   \n",
              "56002    g04-063-03-05     volunteer   \n",
              "...                ...           ...   \n",
              "113093   r03-110-01-09         three   \n",
              "87695    l01-195-01-04          Pete   \n",
              "67069   g06-047l-00-00          This   \n",
              "6457     a02-093-06-05           for   \n",
              "2653    a01-058x-07-03            He   \n",
              "\n",
              "                                          filepath  \n",
              "23187     data/words/c02/c02-022/c02-022-03-01.png  \n",
              "38064     data/words/d06/d06-107/d06-107-08-01.png  \n",
              "20965     data/words/b06/b06-023/b06-023-03-03.png  \n",
              "77141   data/words/h07/h07-063b/h07-063b-00-00.png  \n",
              "56002     data/words/g04/g04-063/g04-063-03-05.png  \n",
              "...                                            ...  \n",
              "113093    data/words/r03/r03-110/r03-110-01-09.png  \n",
              "87695     data/words/l01/l01-195/l01-195-01-04.png  \n",
              "67069   data/words/g06/g06-047l/g06-047l-00-00.png  \n",
              "6457      data/words/a02/a02-093/a02-093-06-05.png  \n",
              "2653    data/words/a01/a01-058x/a01-058x-07-03.png  \n",
              "\n",
              "[48227 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21d6aa76-ba15-48ab-bd2a-0ebbf67f00de\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_id</th>\n",
              "      <th>transcription</th>\n",
              "      <th>filepath</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23187</th>\n",
              "      <td>c02-022-03-01</td>\n",
              "      <td>indignity</td>\n",
              "      <td>data/words/c02/c02-022/c02-022-03-01.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38064</th>\n",
              "      <td>d06-107-08-01</td>\n",
              "      <td>with</td>\n",
              "      <td>data/words/d06/d06-107/d06-107-08-01.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20965</th>\n",
              "      <td>b06-023-03-03</td>\n",
              "      <td>an</td>\n",
              "      <td>data/words/b06/b06-023/b06-023-03-03.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77141</th>\n",
              "      <td>h07-063b-00-00</td>\n",
              "      <td>More</td>\n",
              "      <td>data/words/h07/h07-063b/h07-063b-00-00.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56002</th>\n",
              "      <td>g04-063-03-05</td>\n",
              "      <td>volunteer</td>\n",
              "      <td>data/words/g04/g04-063/g04-063-03-05.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113093</th>\n",
              "      <td>r03-110-01-09</td>\n",
              "      <td>three</td>\n",
              "      <td>data/words/r03/r03-110/r03-110-01-09.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87695</th>\n",
              "      <td>l01-195-01-04</td>\n",
              "      <td>Pete</td>\n",
              "      <td>data/words/l01/l01-195/l01-195-01-04.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67069</th>\n",
              "      <td>g06-047l-00-00</td>\n",
              "      <td>This</td>\n",
              "      <td>data/words/g06/g06-047l/g06-047l-00-00.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6457</th>\n",
              "      <td>a02-093-06-05</td>\n",
              "      <td>for</td>\n",
              "      <td>data/words/a02/a02-093/a02-093-06-05.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2653</th>\n",
              "      <td>a01-058x-07-03</td>\n",
              "      <td>He</td>\n",
              "      <td>data/words/a01/a01-058x/a01-058x-07-03.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>48227 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21d6aa76-ba15-48ab-bd2a-0ebbf67f00de')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-21d6aa76-ba15-48ab-bd2a-0ebbf67f00de button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-21d6aa76-ba15-48ab-bd2a-0ebbf67f00de');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import imghdr\n",
        "\n",
        "data_dir = \"data/words/\"\n",
        "image_extensions = [\".png\"]  # add there all your images file extensions\n",
        "\n",
        "\n",
        "for filepath in Path(data_dir).rglob(\"*\"):\n",
        "    if filepath.suffix.lower() in image_extensions:\n",
        "        img_type = imghdr.what(filepath)\n",
        "        if img_type is None:\n",
        "            print(f\"{filepath} is not an image\")\n",
        "            print(filepath)\n",
        "        elif img_type not in img_type_accepted_by_tf:\n",
        "            print(f\"{filepath} is a {img_type}, not accepted by TensorFlow\")"
      ],
      "metadata": {
        "id": "jDP9ISHGHDTF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee365739-74a9-42a2-895f-76cec616c25f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/words/r06/r06-022/r06-022-03-05.png is not an image\n",
            "data/words/r06/r06-022/r06-022-03-05.png\n",
            "data/words/a01/a01-117/a01-117-05-02.png is not an image\n",
            "data/words/a01/a01-117/a01-117-05-02.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Separation of dataset and Loading + Preprocessing of the image"
      ],
      "metadata": {
        "id": "zIPE0VW26JiS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Loading and preprocessing functions"
      ],
      "metadata": {
        "id": "vAnbbMGLOFzk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pWpXUdw8SX7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "@tf.function\n",
        "def load_image(filepath):\n",
        "    im = tf.io.read_file(filepath)\n",
        "    im = tf.image.decode_png(im, channels=0)\n",
        "\n",
        "    return im\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def preprocess(filepath, imgSize=(32, 128), dataAugmentation=False, scale=0.8, isthreshold=False):\n",
        "\n",
        "\n",
        "\n",
        "    img = load_image(filepath)/255\n",
        "    # there are damaged files in IAM dataset - just use black image instead\n",
        "    if img is None:\n",
        "        img = tf.ones([imgSize[0], imgSize[1], 1])\n",
        "        print(\"None\")\n",
        "\n",
        "    if dataAugmentation:\n",
        "        stretch = scale*(tf.random.uniform([1], 0, 1)[0] - 0.3) # -0.5 .. +0.5\n",
        "        wStretched = tf.maximum(int(float(tf.shape(img)[0]) * (1 + stretch)), 1) # random width, but at least 1\n",
        "        img = tf.image.resize(img, (wStretched, tf.shape(img)[1])) # stretch horizontally by factor 0.5 .. 1.5\n",
        "\n",
        "    (wt, ht) = imgSize\n",
        "\n",
        "    w, h = float(tf.shape(img)[0]), float(tf.shape(img)[1])\n",
        "\n",
        "    fx = w / wt\n",
        "    fy = h / ht\n",
        "\n",
        "    f = tf.maximum(fx, fy)\n",
        "\n",
        "    newSize = (tf.maximum(tf.minimum(wt, int(w / f)), 1), tf.maximum(tf.minimum(ht, int(h / f)), 1)) # scale according to f (result at least 1 and at most wt or ht)\n",
        "\n",
        "    img = tf.image.resize(img, newSize)\n",
        "\n",
        "\n",
        "    dx = wt - newSize[0]\n",
        "    dy = ht - newSize[1]\n",
        "\n",
        "    if dataAugmentation :\n",
        "        dx1=0\n",
        "        dy1=0\n",
        "        if dx!=0:\n",
        "            dx1 = tf.random.uniform([1], 0, dx, tf.int32)[0]\n",
        "        if dy!=0:\n",
        "            dy1 = tf.random.uniform([1], 0, dy, tf.int32)[0]\n",
        "        img = tf.pad(img[..., 0], [[dx1, dx-dx1], [dy1, dy-dy1]], constant_values=1)\n",
        "    else :\n",
        "        img = tf.pad(img[..., 0], [[0, dx], [0, dy]], constant_values=1)\n",
        "\n",
        "    if isthreshold:\n",
        "        return tf.expand_dims(1-(1-img)*tf.cast(img < 0.8, tf.float32), -1)\n",
        "    return tf.expand_dims(img, -1)\n",
        "\n",
        "\n",
        "X_train_path, X_test_path, y_train, y_test = train_test_split(df.filepath.values, df.transcription.values, train_size=0.9, random_state=1234)\n",
        "\n",
        "batch_size = 64\n",
        "imgSize = (32, 128)\n",
        "\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((X_train_path, y_train))\n",
        "dataset_train = dataset_train.shuffle(10000).map(\n",
        "    lambda x, y : [preprocess(x, imgSize, dataAugmentation=True, scale=0.8, isthreshold=True), y]).batch(batch_size, drop_remainder=True)\n",
        "\n",
        "\n",
        "X_t, y_t = next(iter(dataset_train))\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "for j, i in enumerate(np.random.randint(low=0, high=len(X_t), size=[6])):\n",
        "    plt.subplot(2,3,j+1)\n",
        "    plt.imshow(X_t[i][...,0], cmap='gray')\n",
        "    plt.title(y_t[i].numpy().decode('utf'))"
      ],
      "metadata": {
        "id": "OS4BUcr4OE-R"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2xb62bBfsmXD"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorization of the labels"
      ],
      "metadata": {
        "id": "EtznC98Gf-Wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "charList = list(string.ascii_lowercase)\n",
        "\n",
        "def encode_labels(labels):\n",
        "    table = tf.lookup.StaticHashTable(\n",
        "        tf.lookup.KeyValueTensorInitializer(charList, np.arange(len(charList)), value_dtype=tf.int32),\n",
        "        default_value = -1,\n",
        "        name='chard2id')\n",
        "    return table.lookup(tf.compat.v1.string_split(labels, sep=''))\n",
        "\n",
        "\n",
        "def loss(labels, logits):\n",
        "    return tf.reduce_mean(tf.nn.ctc_loss(\n",
        "        labels = labels,\n",
        "        logits = logits,\n",
        "        logit_length = [logits.shape[1]]*logits.shape[0],\n",
        "        label_length = None,\n",
        "        logits_time_major = False,\n",
        "        blank_index=-1))\n",
        "\n",
        "\n",
        "dataset_train = dataset_train.map(lambda X,y : [X, encode_labels(y)])\n",
        "\n",
        "\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((X_test_path, y_test))\n",
        "dataset_test = dataset_test.map(\n",
        "    lambda x, y : [preprocess(x, imgSize, dataAugmentation=True, scale=0.8, isthreshold=True), y]).batch(batch_size, drop_remainder=True)\n",
        "dataset_test = dataset_test.map(lambda X,y : [X, encode_labels(y)])"
      ],
      "metadata": {
        "id": "cLcrDlS_Pbv0"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X_t , y_t in dataset_train:\n",
        "  pass"
      ],
      "metadata": {
        "id": "J2Dcfvp1Pbq5"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelisation"
      ],
      "metadata": {
        "id": "4d_b1CYNwSps"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model_1"
      ],
      "metadata": {
        "id": "vSOxAd01zY5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Input\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "\n",
        "def build_model_1(input_shape,output_vector_length):\n",
        "  ###Lenet model\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(filters=32,\n",
        "                   kernel_size=(3, 3),\n",
        "                   activation='relu',\n",
        "                   input_shape=input_shape))\n",
        "  model.add(layers.MaxPool2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "  model.add(Conv2D(filters=64,\n",
        "                   kernel_size=(3, 3),\n",
        "                   activation='relu',\n",
        "                   padding = 'same'))\n",
        "  model.add(layers.MaxPool2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "  model.add(Conv2D(filters=128,\n",
        "                   kernel_size=(3, 3),\n",
        "                   activation='relu',\n",
        "                   padding = 'valid'))\n",
        "  model.add(layers.MaxPool2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(64,activation =\"relu\"))\n",
        "  model.add(Dense(128,activation =\"relu\"))\n",
        "  model.add(Dense(output_vector_length,activation =\"relu\"))\n",
        "\n",
        "  model\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "HFfhoHpwd43k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_input_shape=(h,w,1)\n",
        "model_1=build_model_1(model_input_shape,max_length)\n",
        "\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbRoe_ryxoZU",
        "outputId": "bcf742ad-823b-4556-b4e3-8d32d7193c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 130, 32)       320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 15, 65, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 15, 65, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 7, 32, 64)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 5, 30, 128)        73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 2, 15, 128)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 3840)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                245824    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 21)                2709      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 349,525\n",
            "Trainable params: 349,525\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jg_g8fAznqmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SQRf53-yd40p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BYUxvwngd4yL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(1,epochs+1),val_acc_lenet,label=\"lenet_validation\")\n",
        "plt.plot(range(1,epochs+1),train_acc_lenet,label=\"lenet_train\")\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "PHkI_qdqyyu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model_2"
      ],
      "metadata": {
        "id": "MWKIODt-6DWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "h,w = 32,128\n",
        "class CTCLayer(keras.layers.Layer):\n",
        "    def __init__(self, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.loss_fn = keras.backend.ctc_batch_cost\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
        "        self.add_loss(loss)\n",
        "\n",
        "        # At test time, just return the computed predictions.\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "def build_model():\n",
        "    # Inputs to the model\n",
        "    input_img = keras.Input(shape=(h, w, 1), name=\"image\")\n",
        "    labels = keras.layers.Input(name=\"label\", shape=(None,))\n",
        "\n",
        "    # First conv block.\n",
        "    x = keras.layers.Conv2D(\n",
        "        32,\n",
        "        (3, 3),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=\"he_normal\",\n",
        "        padding=\"same\",\n",
        "        name=\"Conv1\",\n",
        "    )(input_img)\n",
        "    x = keras.layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n",
        "\n",
        "    # Second conv block.\n",
        "    x = keras.layers.Conv2D(\n",
        "        64,\n",
        "        (3, 3),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=\"he_normal\",\n",
        "        padding=\"same\",\n",
        "        name=\"Conv2\",\n",
        "    )(x)\n",
        "    x = keras.layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n",
        "\n",
        "    # We have used two max pool with pool size and strides 2.\n",
        "    # Hence, downsampled feature maps are 4x smaller. The number of\n",
        "    # filters in the last layer is 64. Reshape accordingly before\n",
        "    # passing the output to the RNN part of the model.\n",
        "    new_shape = ((w // 4), (h // 4) * 64)\n",
        "    x = keras.layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n",
        "    x = keras.layers.Dense(64, activation=\"relu\", name=\"dense1\")(x)\n",
        "    x = keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "    # RNNs.\n",
        "    x = keras.layers.Bidirectional(\n",
        "        keras.layers.LSTM(128, return_sequences=True, dropout=0.25)\n",
        "    )(x)\n",
        "    x = keras.layers.Bidirectional(\n",
        "        keras.layers.LSTM(64, return_sequences=True, dropout=0.25)\n",
        "    )(x)\n",
        "\n",
        "    # +2 is to account for the two special tokens introduced by the CTC loss.\n",
        "    # The recommendation comes here: https://git.io/J0eXP.\n",
        "    x = keras.layers.Dense(\n",
        "        len(le.classes_) + 2, activation=\"softmax\", name=\"dense2\"\n",
        "    )(x)\n",
        "\n",
        "    # Add CTC layer for calculating CTC loss at each step.\n",
        "    output = CTCLayer(name=\"ctc_loss\")(labels, x)\n",
        "\n",
        "    # Define the model.\n",
        "    model = keras.models.Model(\n",
        "        inputs=[input_img,labels], outputs=output, name=\"handwriting_recognizer\"\n",
        "    )\n",
        "    # Optimizer.\n",
        "    opt = keras.optimizers.Adam()\n",
        "    # Compile the model and return.\n",
        "    model.compile(optimizer=opt)\n",
        "    return model\n",
        "\n",
        "\n",
        "# Get the model.\n",
        "model_2 = build_model()\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "KAzuUdGo6G-p",
        "outputId": "27934646-d177-459c-8ffd-e99c73b1cfa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-c1f22cc22163>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;31m# Get the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0mmodel_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0mmodel_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-c1f22cc22163>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# The recommendation comes here: https://git.io/J0eXP.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     x = keras.layers.Dense(\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dense2\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     )(x)\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'le' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "validation_images = []\n",
        "validation_labels = []\n",
        "\n",
        "for batch in validation_ds:\n",
        "    validation_images.append(batch[\"image\"])\n",
        "    validation_labels.append(batch[\"label\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "oKW7xtMs6GzU",
        "outputId": "61ccd9c2-809c-468b-f54c-cbab866736ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-262b078f31e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidation_ds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mvalidation_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "epochs = 10  # To get good results this should be at least 50.\n",
        "\n",
        "model = build_model()\n",
        "prediction_model = keras.models.Model(\n",
        "    model.get_layer(name=\"image\").input, model.get_layer(name=\"dense2\").output\n",
        ")\n",
        "\n",
        "\n",
        "# Train the model.\n",
        "history = model.fit(dataset_train,    \n",
        "                    epochs=epochs)"
      ],
      "metadata": {
        "id": "8abCQDmx6GwP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "dbd4ca91-ea99-437b-e03b-7547d722b628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "171/603 [=======>......................] - ETA: 19s - loss: 18.6990"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-8b173ab4977f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Train the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m history = model.fit(dataset_train,    \n\u001b[0;32m---> 12\u001b[0;31m                     epochs=epochs)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "train_ds =  tf.data.Dataset.from_tensor_slices((X_train_reshaped, y_train_encode))\n",
        "validation_ds = tf.data.Dataset.from_tensor_slices((X_test_reshaped, y_test_encode))"
      ],
      "metadata": {
        "id": "LWqoAYnt6Gty",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "train_ds"
      ],
      "metadata": {
        "id": "z9JQPWez6Gmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "25ce01f8-978b-41ab-e48c-e3f07901e4b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset element_spec=(TensorSpec(shape=(32, 132), dtype=tf.float64, name=None), TensorSpec(shape=(19,), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "re-YDvMayVV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "q6Pof7_FyVS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3ktQIvXVyVP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "yxLZAGi_yVNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EHIywWDOyVLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model_3"
      ],
      "metadata": {
        "id": "sIPromq7Pncu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, LeakyReLU, Dropout\n",
        "from tensorflow.keras.layers import GRU, Bidirectional, Dense, Lambda\n",
        "numHidden = 256\n",
        "\n",
        "def build_model_3():\n",
        "  #Create_model_CRNN\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # Layer 1\n",
        "    model.add(Conv2D(filters=32, kernel_size=(5,5), padding='SAME', input_shape = X_t.shape[1:]))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    # Layer 2\n",
        "    model.add(Conv2D(filters=64, kernel_size=(5,5), padding='SAME'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    # Layer 3\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding='SAME'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(MaxPooling2D(pool_size=(2,1), strides=(2,1)))\n",
        "\n",
        "    # Layer 4\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding='SAME'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(MaxPooling2D(pool_size=(2,1), strides=(2,1)))\n",
        "\n",
        "    # Layer 5\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding='SAME'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(MaxPooling2D(pool_size=(2,1), strides=(2,1)))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "\n",
        "    model.add(Lambda(lambda x :tf.squeeze(x, axis=1)))\n",
        "\n",
        "    # Bidirectionnal RNN\n",
        "    model.add(Bidirectional(GRU(numHidden, return_sequences=True)))\n",
        "    # Classification of characters\n",
        "    model.add(Dense(len(charList)+1))\n",
        "    return model\n",
        "\n",
        "model_3 = build_model_3()\n",
        "model_3.summary()"
      ],
      "metadata": {
        "id": "cz1nUiqCPtpA",
        "outputId": "0fb85e8c-fb75-42d4-c596-286fd3bac8b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 128, 32)       832       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 128, 32)      128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 32, 128, 32)       0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 64, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 64, 64)        51264     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 16, 64, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 16, 64, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 32, 64)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 32, 128)        73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 8, 32, 128)       512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 8, 32, 128)        0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 32, 128)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 32, 128)        147584    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 4, 32, 128)       512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 4, 32, 128)        0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 2, 32, 128)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 2, 32, 256)        295168    \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 2, 32, 256)       1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 2, 32, 256)        0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 1, 32, 256)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1, 32, 256)        0         \n",
            "                                                                 \n",
            " lambda (Lambda)             (None, 32, 256)           0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 32, 512)          789504    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32, 27)            13851     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,374,491\n",
            "Trainable params: 1,373,275\n",
            "Non-trainable params: 1,216\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PuP67iCKPtmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MpG1K5CQPszw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compilation"
      ],
      "metadata": {
        "id": "TSQ20YVBwZSt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model_1"
      ],
      "metadata": {
        "id": "VgH8b6jIw18N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.compile(optimizer = Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "pwvjaF0awenZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kiiGfQ3kw7dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lnhzH6E6w7aO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model_2"
      ],
      "metadata": {
        "id": "yfyGffgbw4wo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yV_euQJIwefr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QcG-1XHQw6zU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rkDYHkxRw6uH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model_3"
      ],
      "metadata": {
        "id": "PujbUbKyQGMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "model_3.compile(optimizer=Adam(1e-3),loss=loss)"
      ],
      "metadata": {
        "id": "YDlUnu2CQH3D"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kd1vym1VQHz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "qBfF_gl8QHxJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a169e37a-3a76-4ba7-c9db-3bbb6c0a2f8f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset element_spec=(TensorSpec(shape=(64, None, None, 1), dtype=tf.float32, name=None), SparseTensorSpec(TensorShape([None, None]), tf.int32))>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "KASxMI-Rwr1w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model_1"
      ],
      "metadata": {
        "id": "UU5uVhdrQY6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=5\n",
        "training_history_model_1=model_1.fit(X_train_reshaped,y_train_encode,epochs=epochs,batch_size=150, validation_data = (X_test_reshaped,y_test_encode))"
      ],
      "metadata": {
        "id": "HJZudvcFwtz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc_model_1 = training_history_lenet.history['accuracy']\n",
        "val_acc_model_1 = training_history_lenet.history['val_accuracy']"
      ],
      "metadata": {
        "id": "q3kc8_e4wtst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model_3"
      ],
      "metadata": {
        "id": "_olz0nqLQaw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_history=model_3.fit(dataset_train,epochs=10, validation_data=dataset_test)"
      ],
      "metadata": {
        "id": "aAvh8CToQc5C",
        "outputId": "27bda50e-7ddf-4de1-926a-d14ec7404c98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "678/678 [==============================] - 53s 77ms/step - loss: 11.9574 - val_loss: 12.1750\n",
            "Epoch 2/10\n",
            "678/678 [==============================] - 48s 71ms/step - loss: 11.9426 - val_loss: 12.9104\n",
            "Epoch 3/10\n",
            "678/678 [==============================] - 46s 67ms/step - loss: 12.0813 - val_loss: 11.9568\n",
            "Epoch 4/10\n",
            "678/678 [==============================] - 46s 68ms/step - loss: 11.8837 - val_loss: 12.0603\n",
            "Epoch 5/10\n",
            "678/678 [==============================] - 48s 71ms/step - loss: 12.1299 - val_loss: 12.1404\n",
            "Epoch 6/10\n",
            "678/678 [==============================] - 47s 69ms/step - loss: 12.0539 - val_loss: 25.0990\n",
            "Epoch 7/10\n",
            "678/678 [==============================] - 47s 69ms/step - loss: 11.9607 - val_loss: 12.0647\n",
            "Epoch 8/10\n",
            "678/678 [==============================] - 47s 69ms/step - loss: 12.1061 - val_loss: 12.3607\n",
            "Epoch 9/10\n",
            "678/678 [==============================] - 46s 67ms/step - loss: 12.0290 - val_loss: 12.4685\n",
            "Epoch 10/10\n",
            "678/678 [==============================] - 48s 71ms/step - loss: 12.0081 - val_loss: 12.0925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qy11fIhRQc12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model_3.predict(dataset_test)"
      ],
      "metadata": {
        "id": "R6Bt2UJJUcL9",
        "outputId": "c3abbb41-7df8-4ab9-8cff-b24cb03cfad2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75/75 [==============================] - 6s 78ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred[0][0]+3115"
      ],
      "metadata": {
        "id": "JfXFgIaeQcy8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5e723ce-6c3b-4bc1-de00-cdb488fe2678"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.74731445, -0.5637207 , -0.15649414, -0.1940918 ,  0.96069336,\n",
              "       -0.265625  , -0.87597656,  0.24658203,  0.23706055, -2.7404785 ,\n",
              "       -1.2626953 , -0.07226562, -0.6308594 ,  0.15649414,  0.5751953 ,\n",
              "       -0.8720703 , -2.8825684 ,  0.45043945,  0.17480469,  0.78637695,\n",
              "       -0.36523438, -1.1586914 , -0.66064453, -2.340332  , -0.7565918 ,\n",
              "       -3.3217773 ,  4.7070312 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decode the vector"
      ],
      "metadata": {
        "id": "FPRodf3hy6BF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_codes(codes):\n",
        "    table = tf.lookup.StaticHashTable(\n",
        "        tf.lookup.KeyValueTensorInitializer(\n",
        "            np.arange(len(charList)),\n",
        "            charList,\n",
        "            key_dtype=tf.int32\n",
        "        ),\n",
        "        '',\n",
        "        name='id2char'\n",
        "    )\n",
        "    return table.lookup(codes)\n",
        "\n",
        "b = decode_codes(encode_labels(y_train[0:5]))\n",
        "b.values"
      ],
      "metadata": {
        "id": "cOpqRc60yyde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "poycif5Xxjk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "Wl-T6thUQrNs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oR3oqvIaQsK_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}