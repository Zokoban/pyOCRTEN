{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vSOxAd01zY5-"
      ],
      "authorship_tag": "ABX9TyPKkUZp/dGpIqgS/gPZdryY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zokoban/pyOCRTEN/blob/Full_TensorFlow/ocr_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download all data on the drive "
      ],
      "metadata": {
        "id": "rY2t8iv40Atm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://git.io/J0fjL -O IAM_Words.zip\n",
        "!unzip -qq IAM_Words.zip\n",
        "!\n",
        "!mkdir data\n",
        "!mkdir data/words\n",
        "!tar -xf IAM_Words/words.tgz -C data/words\n",
        "!mv IAM_Words/words.txt data"
      ],
      "metadata": {
        "id": "pQd5d8OitoDO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load all the required packages"
      ],
      "metadata": {
        "id": "TQBEwYLH0FP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "PiYqf_7Uz_YR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load word.txt file"
      ],
      "metadata": {
        "id": "Xiv8jaZB0LZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_txt=pd.read_csv(\"data/words.txt\", \n",
        "                     sep=' ', \n",
        "                     names=[\"word_id\",\"segmentation_result\",\"gray_level\",\"x\",\"y\",\"pxw\",\"pxh\",\"grammatical_tag\",\"transcription_1\",\"transcription_2\",\"transcription_3\"], \n",
        "                     quoting=csv.QUOTE_NONE, \n",
        "                     skiprows=18, \n",
        "                     on_bad_lines=\"warn\")\n",
        "\n",
        "def f(x):\n",
        "    if x == \"nan\":\n",
        "        return \"\"\n",
        "    else:\n",
        "        return x\n",
        "word_txt[\"transcription\"]=word_txt.transcription_1.astype(\"str\")+word_txt.transcription_2.astype(\"str\").apply(f)+word_txt.transcription_3.astype(\"str\").apply(f)\n",
        "word_txt=word_txt.drop(columns=[\"transcription_1\",\"transcription_2\",\"transcription_3\"])\n",
        "\n",
        "def f(x):\n",
        "    return len(x)\n",
        "\n",
        "word_txt[\"number_components\"]=word_txt.transcription.apply(f)\n",
        "\n",
        "print(\"word_txt Length: \",len(word_txt))\n",
        "word_txt.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "mWa3zM2KvL5q",
        "outputId": "d58372c0-7bb8-42ca-c5d6-2d723f14ba35"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word_txt Length:  115320\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          word_id segmentation_result  gray_level     x    y  pxw  pxh  \\\n",
              "0  a01-000u-00-00                  ok         154   408  768   27   51   \n",
              "1  a01-000u-00-01                  ok         154   507  766  213   48   \n",
              "2  a01-000u-00-02                  ok         154   796  764   70   50   \n",
              "3  a01-000u-00-03                  ok         154   919  757  166   78   \n",
              "4  a01-000u-00-04                  ok         154  1185  754  126   61   \n",
              "\n",
              "  grammatical_tag transcription  number_components  \n",
              "0              AT             A                  1  \n",
              "1              NN          MOVE                  4  \n",
              "2              TO            to                  2  \n",
              "3              VB          stop                  4  \n",
              "4             NPT           Mr.                  3  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b727866-42bd-4a6d-a400-cccc7fc70205\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_id</th>\n",
              "      <th>segmentation_result</th>\n",
              "      <th>gray_level</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>pxw</th>\n",
              "      <th>pxh</th>\n",
              "      <th>grammatical_tag</th>\n",
              "      <th>transcription</th>\n",
              "      <th>number_components</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a01-000u-00-00</td>\n",
              "      <td>ok</td>\n",
              "      <td>154</td>\n",
              "      <td>408</td>\n",
              "      <td>768</td>\n",
              "      <td>27</td>\n",
              "      <td>51</td>\n",
              "      <td>AT</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a01-000u-00-01</td>\n",
              "      <td>ok</td>\n",
              "      <td>154</td>\n",
              "      <td>507</td>\n",
              "      <td>766</td>\n",
              "      <td>213</td>\n",
              "      <td>48</td>\n",
              "      <td>NN</td>\n",
              "      <td>MOVE</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a01-000u-00-02</td>\n",
              "      <td>ok</td>\n",
              "      <td>154</td>\n",
              "      <td>796</td>\n",
              "      <td>764</td>\n",
              "      <td>70</td>\n",
              "      <td>50</td>\n",
              "      <td>TO</td>\n",
              "      <td>to</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a01-000u-00-03</td>\n",
              "      <td>ok</td>\n",
              "      <td>154</td>\n",
              "      <td>919</td>\n",
              "      <td>757</td>\n",
              "      <td>166</td>\n",
              "      <td>78</td>\n",
              "      <td>VB</td>\n",
              "      <td>stop</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a01-000u-00-04</td>\n",
              "      <td>ok</td>\n",
              "      <td>154</td>\n",
              "      <td>1185</td>\n",
              "      <td>754</td>\n",
              "      <td>126</td>\n",
              "      <td>61</td>\n",
              "      <td>NPT</td>\n",
              "      <td>Mr.</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b727866-42bd-4a6d-a400-cccc7fc70205')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b727866-42bd-4a6d-a400-cccc7fc70205 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b727866-42bd-4a6d-a400-cccc7fc70205');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Choice of the fraction of the dataset.\n",
        "### Removal of the transcription error.\n",
        "### Removal of the unwanted columns."
      ],
      "metadata": {
        "id": "4teX3LNn3BJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import imghdr\n",
        "\n",
        "fraction = 1\n",
        "\n",
        "data_dir = \"data/words/\"\n",
        "image_extensions = [\".png\"]  # add there all your images file extensions\n",
        "img_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\"]\n",
        "\n",
        "def img_path(word):\n",
        "    path=data_dir+word.split(\"-\")[0]+\"/\"+word.split(\"-\")[0]+\"-\"+word.split(\"-\")[1]+\"/\"+word+\".png\"\n",
        "    \n",
        "    return path\n",
        "\n",
        "def removal_of_corrupt_image(df):\n",
        "  index_to_drop=[]\n",
        "  for filepath in Path(data_dir).rglob(\"*\"):\n",
        "      if filepath.suffix.lower() in image_extensions:\n",
        "          img_type = imghdr.what(filepath)\n",
        "          if img_type is None:\n",
        "              index_to_drop.append(df[df.filepath==str(filepath)].index)\n",
        "              df=df.drop(labels=df[df.filepath==str(filepath)].index)\n",
        "              print(f\"{filepath} is not an image\")\n",
        "          elif img_type not in img_type_accepted_by_tf:\n",
        "              df=df.drop(labels=df[df.filepath==str(filepath)].index)\n",
        "              print(f\"{filepath} is a {img_type}, not accepted by TensorFlow and is drop\")\n",
        "  return df\n",
        "\n",
        "list_columns_to_remove=[\"segmentation_result\",\"gray_level\",\"x\",\"y\",\"pxw\",\"pxh\",\"grammatical_tag\",\"number_components\"]\n",
        "\n",
        "df = word_txt[word_txt.segmentation_result == \"ok\"]\\\n",
        "    .drop(columns=list_columns_to_remove)\\\n",
        "    .sample(frac=fraction)\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "print(\"df Length: \",len(df))\n",
        "df[\"filepath\"]=df.word_id.apply(img_path)\n",
        "df=removal_of_corrupt_image(df)\n",
        "print(\"df Length: \",len(df))\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "EHQ1vKx53Wbj",
        "outputId": "823d745c-9245-4816-834d-8d113b1804c2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df Length:  96456\n",
            "data/words/r06/r06-022/r06-022-03-05.png is not an image\n",
            "data/words/a01/a01-117/a01-117-05-02.png is not an image\n",
            "df Length:  96454\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              word_id transcription  \\\n",
              "21137   b06-036-01-01       Britain   \n",
              "74463   h04-082-08-01           and   \n",
              "97054   m04-190-00-02             ,   \n",
              "66683  g06-047f-00-10     described   \n",
              "67088  g06-047l-02-00             '   \n",
              "\n",
              "                                         filepath  \n",
              "21137    data/words/b06/b06-036/b06-036-01-01.png  \n",
              "74463    data/words/h04/h04-082/h04-082-08-01.png  \n",
              "97054    data/words/m04/m04-190/m04-190-00-02.png  \n",
              "66683  data/words/g06/g06-047f/g06-047f-00-10.png  \n",
              "67088  data/words/g06/g06-047l/g06-047l-02-00.png  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f8960e34-e983-4580-8ad1-90508bf3298e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_id</th>\n",
              "      <th>transcription</th>\n",
              "      <th>filepath</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21137</th>\n",
              "      <td>b06-036-01-01</td>\n",
              "      <td>Britain</td>\n",
              "      <td>data/words/b06/b06-036/b06-036-01-01.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74463</th>\n",
              "      <td>h04-082-08-01</td>\n",
              "      <td>and</td>\n",
              "      <td>data/words/h04/h04-082/h04-082-08-01.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97054</th>\n",
              "      <td>m04-190-00-02</td>\n",
              "      <td>,</td>\n",
              "      <td>data/words/m04/m04-190/m04-190-00-02.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66683</th>\n",
              "      <td>g06-047f-00-10</td>\n",
              "      <td>described</td>\n",
              "      <td>data/words/g06/g06-047f/g06-047f-00-10.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67088</th>\n",
              "      <td>g06-047l-02-00</td>\n",
              "      <td>'</td>\n",
              "      <td>data/words/g06/g06-047l/g06-047l-02-00.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8960e34-e983-4580-8ad1-90508bf3298e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f8960e34-e983-4580-8ad1-90508bf3298e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f8960e34-e983-4580-8ad1-90508bf3298e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Separation of dataset and Loading + Preprocessing of the image"
      ],
      "metadata": {
        "id": "zIPE0VW26JiS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Loading and preprocessing functions"
      ],
      "metadata": {
        "id": "vAnbbMGLOFzk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pWpXUdw8SX7N"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "imgSize = (32, 128)\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "@tf.function\n",
        "def load_image(filepath):\n",
        "    im = tf.io.read_file(filepath)\n",
        "    im = tf.image.decode_png(im, channels=0)\n",
        "\n",
        "    return im\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def preprocess(filepath, imgSize=(32, 128), dataAugmentation=False, scale=0.8, isthreshold=False):\n",
        "\n",
        "\n",
        "\n",
        "    img = load_image(filepath)/255\n",
        "    # there are damaged files in IAM dataset - just use black image instead\n",
        "    if img is None:\n",
        "        img = tf.ones([imgSize[0], imgSize[1], 1])\n",
        "        print(\"None\")\n",
        "\n",
        "    if dataAugmentation:\n",
        "        stretch = scale*(tf.random.uniform([1], 0, 1)[0] - 0.3) # -0.5 .. +0.5\n",
        "        wStretched = tf.maximum(int(float(tf.shape(img)[0]) * (1 + stretch)), 1) # random width, but at least 1\n",
        "        img = tf.image.resize(img, (wStretched, tf.shape(img)[1])) # stretch horizontally by factor 0.5 .. 1.5\n",
        "\n",
        "    (wt, ht) = imgSize\n",
        "\n",
        "    w, h = float(tf.shape(img)[0]), float(tf.shape(img)[1])\n",
        "\n",
        "    fx = w / wt\n",
        "    fy = h / ht\n",
        "\n",
        "    f = tf.maximum(fx, fy)\n",
        "\n",
        "    newSize = (tf.maximum(tf.minimum(wt, int(w / f)), 1), tf.maximum(tf.minimum(ht, int(h / f)), 1)) # scale according to f (result at least 1 and at most wt or ht)\n",
        "\n",
        "    img = tf.image.resize(img, newSize)\n",
        "\n",
        "\n",
        "    dx = wt - newSize[0]\n",
        "    dy = ht - newSize[1]\n",
        "\n",
        "    if dataAugmentation :\n",
        "        dx1=0\n",
        "        dy1=0\n",
        "        if dx!=0:\n",
        "            dx1 = tf.random.uniform([1], 0, dx, tf.int32)[0]\n",
        "        if dy!=0:\n",
        "            dy1 = tf.random.uniform([1], 0, dy, tf.int32)[0]\n",
        "        img = tf.pad(img[..., 0], [[dx1, dx-dx1], [dy1, dy-dy1]], constant_values=0)\n",
        "    else :\n",
        "        img = tf.pad(img[..., 0], [[0, dx], [0, dy]], constant_values=0)\n",
        "\n",
        "    if isthreshold:\n",
        "        return tf.expand_dims(1-(1-img)*tf.cast(img < 0.8, tf.float32), -1)\n",
        "    return tf.expand_dims(img, -1)\n",
        "\n",
        "\n",
        "X_train_path, X_test_path, y_train, y_test = train_test_split(df.filepath.values, df.transcription.values, train_size=0.9, random_state=1234)\n",
        "\n",
        "\n",
        "\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((X_train_path, y_train))\n",
        "dataset_train = dataset_train.shuffle(10000).map(\n",
        "    lambda x, y : [preprocess(x, imgSize, dataAugmentation=True, scale=0.8, isthreshold=True), y]).batch(batch_size, drop_remainder=True)\n",
        "\n",
        "\n",
        "X_t, y_t = next(iter(dataset_train))\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "for j, i in enumerate(np.random.randint(low=0, high=len(X_t), size=[6])):\n",
        "    plt.subplot(2,3,j+1)\n",
        "    plt.imshow(X_t[i][...,0], cmap='gray')\n",
        "    plt.title(y_t[i].numpy().decode('utf'))"
      ],
      "metadata": {
        "id": "OS4BUcr4OE-R",
        "outputId": "fdae6b2f-7d04-45dc-d043-9a2c250b4ffa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2xb62bBfsmXD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorization of the labels"
      ],
      "metadata": {
        "id": "EtznC98Gf-Wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "charList = list(string.ascii_lowercase)\n",
        "\n",
        "def encode_labels(labels):\n",
        "    table = tf.lookup.StaticHashTable(\n",
        "        tf.lookup.KeyValueTensorInitializer(charList, np.arange(len(charList)), value_dtype=tf.int32),\n",
        "        default_value = -1,\n",
        "        name='chard2id')\n",
        "    return table.lookup(tf.compat.v1.string_split(labels, sep=''))\n",
        "\n",
        "\n",
        "def loss(labels, logits):\n",
        "    return tf.reduce_mean(tf.nn.ctc_loss(\n",
        "        labels = labels,\n",
        "        logits = logits,\n",
        "        logit_length = [logits.shape[1]]*logits.shape[0],\n",
        "        label_length = None,\n",
        "        logits_time_major = False,\n",
        "        blank_index=-1))\n",
        "\n",
        "\n",
        "dataset_train = dataset_train.map(lambda X,y : [X, encode_labels(y)])\n",
        "\n",
        "\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((X_test_path, y_test))\n",
        "dataset_test = dataset_test.map(\n",
        "    lambda x, y : [preprocess(x, imgSize, dataAugmentation=True, scale=0.8, isthreshold=True), y]).batch(batch_size, drop_remainder=True)\n",
        "dataset_test = dataset_test.map(lambda X,y : [X, encode_labels(y)])"
      ],
      "metadata": {
        "id": "cLcrDlS_Pbv0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = encode_labels(y_train[:10])\n",
        "\n",
        "print(y_train[:10])\n",
        "tf.sparse.to_dense(a).numpy()"
      ],
      "metadata": {
        "id": "Ak4RUOdDeS-w",
        "outputId": "4d54c19f-2179-4590-9eb8-d242ec54ad9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['by' 'only' 'majorities' 'his' 'which' 'army' 'mediaeval' 'clear' 'child'\n",
            " 'he']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1, 24,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [14, 13, 11, 24,  0,  0,  0,  0,  0,  0],\n",
              "       [12,  0,  9, 14, 17,  8, 19,  8,  4, 18],\n",
              "       [ 7,  8, 18,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [22,  7,  8,  2,  7,  0,  0,  0,  0,  0],\n",
              "       [ 0, 17, 12, 24,  0,  0,  0,  0,  0,  0],\n",
              "       [12,  4,  3,  8,  0,  4, 21,  0, 11,  0],\n",
              "       [ 2, 11,  4,  0, 17,  0,  0,  0,  0,  0],\n",
              "       [ 2,  7,  8, 11,  3,  0,  0,  0,  0,  0],\n",
              "       [ 7,  4,  0,  0,  0,  0,  0,  0,  0,  0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelisation"
      ],
      "metadata": {
        "id": "4d_b1CYNwSps"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model_1"
      ],
      "metadata": {
        "id": "vSOxAd01zY5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Input\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "\n",
        "def build_model_1(input_shape,output_vector_length):\n",
        "  ###Lenet model\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(filters=32,\n",
        "                   kernel_size=(3, 3),\n",
        "                   activation='relu',\n",
        "                   input_shape=input_shape))\n",
        "  model.add(layers.MaxPool2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "  model.add(Conv2D(filters=64,\n",
        "                   kernel_size=(3, 3),\n",
        "                   activation='relu',\n",
        "                   padding = 'same'))\n",
        "  model.add(layers.MaxPool2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "  model.add(Conv2D(filters=128,\n",
        "                   kernel_size=(3, 3),\n",
        "                   activation='relu',\n",
        "                   padding = 'valid'))\n",
        "  model.add(layers.MaxPool2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(64,activation =\"relu\"))\n",
        "  model.add(Dense(128,activation =\"relu\"))\n",
        "  model.add(Dense(output_vector_length,activation =\"relu\"))\n",
        "\n",
        "  model\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "HFfhoHpwd43k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_input_shape=(h,w,1)\n",
        "model_1=build_model_1(model_input_shape,max_length)\n",
        "\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbRoe_ryxoZU",
        "outputId": "bcf742ad-823b-4556-b4e3-8d32d7193c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 130, 32)       320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 15, 65, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 15, 65, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 7, 32, 64)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 5, 30, 128)        73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 2, 15, 128)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 3840)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                245824    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 21)                2709      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 349,525\n",
            "Trainable params: 349,525\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jg_g8fAznqmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SQRf53-yd40p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BYUxvwngd4yL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(1,epochs+1),val_acc_lenet,label=\"lenet_validation\")\n",
        "plt.plot(range(1,epochs+1),train_acc_lenet,label=\"lenet_train\")\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "PHkI_qdqyyu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model_2"
      ],
      "metadata": {
        "id": "MWKIODt-6DWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "h,w = 32,128\n",
        "class CTCLayer(keras.layers.Layer):\n",
        "    def __init__(self, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.loss_fn = keras.backend.ctc_batch_cost\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
        "        self.add_loss(loss)\n",
        "\n",
        "        # At test time, just return the computed predictions.\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "def build_model():\n",
        "    # Inputs to the model\n",
        "    input_img = keras.Input(shape=(h, w, 1), name=\"image\")\n",
        "    labels = keras.layers.Input(name=\"label\", shape=(None,))\n",
        "\n",
        "    # First conv block.\n",
        "    x = keras.layers.Conv2D(\n",
        "        32,\n",
        "        (3, 3),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=\"he_normal\",\n",
        "        padding=\"same\",\n",
        "        name=\"Conv1\",\n",
        "    )(input_img)\n",
        "    x = keras.layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n",
        "\n",
        "    # Second conv block.\n",
        "    x = keras.layers.Conv2D(\n",
        "        64,\n",
        "        (3, 3),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=\"he_normal\",\n",
        "        padding=\"same\",\n",
        "        name=\"Conv2\",\n",
        "    )(x)\n",
        "    x = keras.layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n",
        "\n",
        "    # We have used two max pool with pool size and strides 2.\n",
        "    # Hence, downsampled feature maps are 4x smaller. The number of\n",
        "    # filters in the last layer is 64. Reshape accordingly before\n",
        "    # passing the output to the RNN part of the model.\n",
        "    new_shape = ((w // 4), (h // 4) * 64)\n",
        "    x = keras.layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n",
        "    x = keras.layers.Dense(64, activation=\"relu\", name=\"dense1\")(x)\n",
        "    x = keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "    # RNNs.\n",
        "    x = keras.layers.Bidirectional(\n",
        "        keras.layers.LSTM(128, return_sequences=True, dropout=0.25)\n",
        "    )(x)\n",
        "    x = keras.layers.Bidirectional(\n",
        "        keras.layers.LSTM(64, return_sequences=True, dropout=0.25)\n",
        "    )(x)\n",
        "\n",
        "    # +2 is to account for the two special tokens introduced by the CTC loss.\n",
        "    # The recommendation comes here: https://git.io/J0eXP.\n",
        "    x = keras.layers.Dense(\n",
        "        len(le.classes_) + 2, activation=\"softmax\", name=\"dense2\"\n",
        "    )(x)\n",
        "\n",
        "    # Add CTC layer for calculating CTC loss at each step.\n",
        "    output = CTCLayer(name=\"ctc_loss\")(labels, x)\n",
        "\n",
        "    # Define the model.\n",
        "    model = keras.models.Model(\n",
        "        inputs=[input_img,labels], outputs=output, name=\"handwriting_recognizer\"\n",
        "    )\n",
        "    # Optimizer.\n",
        "    opt = keras.optimizers.Adam()\n",
        "    # Compile the model and return.\n",
        "    model.compile(optimizer=opt)\n",
        "    return model\n",
        "\n",
        "\n",
        "# Get the model.\n",
        "model_2 = build_model()\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "KAzuUdGo6G-p",
        "outputId": "27934646-d177-459c-8ffd-e99c73b1cfa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-c1f22cc22163>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;31m# Get the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0mmodel_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0mmodel_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-c1f22cc22163>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# The recommendation comes here: https://git.io/J0eXP.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     x = keras.layers.Dense(\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dense2\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     )(x)\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'le' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "validation_images = []\n",
        "validation_labels = []\n",
        "\n",
        "for batch in validation_ds:\n",
        "    validation_images.append(batch[\"image\"])\n",
        "    validation_labels.append(batch[\"label\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "oKW7xtMs6GzU",
        "outputId": "61ccd9c2-809c-468b-f54c-cbab866736ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-262b078f31e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidation_ds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mvalidation_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "epochs = 10  # To get good results this should be at least 50.\n",
        "\n",
        "model = build_model()\n",
        "prediction_model = keras.models.Model(\n",
        "    model.get_layer(name=\"image\").input, model.get_layer(name=\"dense2\").output\n",
        ")\n",
        "\n",
        "\n",
        "# Train the model.\n",
        "history = model.fit(dataset_train,    \n",
        "                    epochs=epochs)"
      ],
      "metadata": {
        "id": "8abCQDmx6GwP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "dbd4ca91-ea99-437b-e03b-7547d722b628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "171/603 [=======>......................] - ETA: 19s - loss: 18.6990"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-8b173ab4977f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Train the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m history = model.fit(dataset_train,    \n\u001b[0;32m---> 12\u001b[0;31m                     epochs=epochs)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "train_ds =  tf.data.Dataset.from_tensor_slices((X_train_reshaped, y_train_encode))\n",
        "validation_ds = tf.data.Dataset.from_tensor_slices((X_test_reshaped, y_test_encode))"
      ],
      "metadata": {
        "id": "LWqoAYnt6Gty",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "train_ds"
      ],
      "metadata": {
        "id": "z9JQPWez6Gmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "25ce01f8-978b-41ab-e48c-e3f07901e4b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset element_spec=(TensorSpec(shape=(32, 132), dtype=tf.float64, name=None), TensorSpec(shape=(19,), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "re-YDvMayVV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "q6Pof7_FyVS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3ktQIvXVyVP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "yxLZAGi_yVNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EHIywWDOyVLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model_3"
      ],
      "metadata": {
        "id": "sIPromq7Pncu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, LeakyReLU, Dropout\n",
        "from tensorflow.keras.layers import GRU, Bidirectional, Dense, Lambda\n",
        "numHidden = 256\n",
        "\n",
        "def build_model_3():\n",
        "  #Create_model_CRNN\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # Layer 1\n",
        "    model.add(Conv2D(filters=32, kernel_size=(5,5), padding='SAME', input_shape = X_t.shape[1:]))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    # Layer 2\n",
        "    model.add(Conv2D(filters=64, kernel_size=(5,5), padding='SAME'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    # Layer 3\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding='SAME'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(MaxPooling2D(pool_size=(2,1), strides=(2,1)))\n",
        "\n",
        "    # Layer 4\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding='SAME'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(MaxPooling2D(pool_size=(2,1), strides=(2,1)))\n",
        "\n",
        "    # Layer 5\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding='SAME'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(MaxPooling2D(pool_size=(2,1), strides=(2,1)))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "\n",
        "    model.add(Lambda(lambda x :tf.squeeze(x, axis=1)))\n",
        "\n",
        "    # Bidirectionnal RNN\n",
        "    model.add(Bidirectional(GRU(numHidden, return_sequences=True)))\n",
        "    # Classification of characters\n",
        "    model.add(Dense(len(charList)+1))\n",
        "    return model\n",
        "\n",
        "model_3 = build_model_3()\n",
        "model_3.summary()"
      ],
      "metadata": {
        "id": "cz1nUiqCPtpA",
        "outputId": "c93261fd-565e-4351-ab59-a88d1df2be62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_30 (Conv2D)          (None, 32, 128, 32)       832       \n",
            "                                                                 \n",
            " batch_normalization_30 (Bat  (None, 32, 128, 32)      128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_30 (LeakyReLU)  (None, 32, 128, 32)       0         \n",
            "                                                                 \n",
            " max_pooling2d_30 (MaxPoolin  (None, 16, 64, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 16, 64, 64)        51264     \n",
            "                                                                 \n",
            " batch_normalization_31 (Bat  (None, 16, 64, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_31 (LeakyReLU)  (None, 16, 64, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_31 (MaxPoolin  (None, 8, 32, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 8, 32, 128)        73856     \n",
            "                                                                 \n",
            " batch_normalization_32 (Bat  (None, 8, 32, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_32 (LeakyReLU)  (None, 8, 32, 128)        0         \n",
            "                                                                 \n",
            " max_pooling2d_32 (MaxPoolin  (None, 4, 32, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 4, 32, 128)        147584    \n",
            "                                                                 \n",
            " batch_normalization_33 (Bat  (None, 4, 32, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_33 (LeakyReLU)  (None, 4, 32, 128)        0         \n",
            "                                                                 \n",
            " max_pooling2d_33 (MaxPoolin  (None, 2, 32, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (None, 2, 32, 256)        295168    \n",
            "                                                                 \n",
            " batch_normalization_34 (Bat  (None, 2, 32, 256)       1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_34 (LeakyReLU)  (None, 2, 32, 256)        0         \n",
            "                                                                 \n",
            " max_pooling2d_34 (MaxPoolin  (None, 1, 32, 256)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 1, 32, 256)        0         \n",
            "                                                                 \n",
            " lambda_6 (Lambda)           (None, 32, 256)           0         \n",
            "                                                                 \n",
            " bidirectional_6 (Bidirectio  (None, 32, 512)          789504    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 32, 27)            13851     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,374,491\n",
            "Trainable params: 1,373,275\n",
            "Non-trainable params: 1,216\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PuP67iCKPtmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MpG1K5CQPszw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compilation"
      ],
      "metadata": {
        "id": "TSQ20YVBwZSt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model_3"
      ],
      "metadata": {
        "id": "PujbUbKyQGMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "model_3.compile(optimizer=Adam(1e-3),loss=loss)"
      ],
      "metadata": {
        "id": "YDlUnu2CQH3D"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "KASxMI-Rwr1w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model_2\n"
      ],
      "metadata": {
        "id": "9rXsh7PWgYlK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train"
      ],
      "metadata": {
        "id": "9z0d5vyDhhJ0",
        "outputId": "9f639593-9a0e-4479-877d-b5af41f01ac9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset element_spec=(TensorSpec(shape=(128, None, None, 1), dtype=tf.float32, name=None), SparseTensorSpec(TensorShape([None, None]), tf.int32))>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_ds = dataset_train.map(lambda X,y:{\"image\":X,\"label\":y})"
      ],
      "metadata": {
        "id": "6l2gZB5wgame"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as keras\n",
        "\n",
        "class CTCLayer(keras.layers.Layer):\n",
        "    def __init__(self, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.loss_fn = keras.backend.ctc_batch_cost\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
        "        self.add_loss(loss)\n",
        "\n",
        "        # At test time, just return the computed predictions.\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "def build_model():\n",
        "    image_width=128\n",
        "    image_height=32\n",
        "    # Inputs to the model\n",
        "    input_img = keras.Input(shape=(128, 32, 1), name=\"image\")\n",
        "    labels = keras.layers.Input(name=\"label\", shape=(None,))\n",
        "\n",
        "    # First conv block.\n",
        "    x = keras.layers.Conv2D(\n",
        "        32,\n",
        "        (3, 3),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=\"he_normal\",\n",
        "        padding=\"same\",\n",
        "        name=\"Conv1\",\n",
        "    )(input_img)\n",
        "    x = keras.layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n",
        "\n",
        "    # Second conv block.\n",
        "    x = keras.layers.Conv2D(\n",
        "        64,\n",
        "        (3, 3),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=\"he_normal\",\n",
        "        padding=\"same\",\n",
        "        name=\"Conv2\",\n",
        "    )(x)\n",
        "    x = keras.layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n",
        "\n",
        "    # We have used two max pool with pool size and strides 2.\n",
        "    # Hence, downsampled feature maps are 4x smaller. The number of\n",
        "    # filters in the last layer is 64. Reshape accordingly before\n",
        "    # passing the output to the RNN part of the model.\n",
        "    new_shape = ((image_width // 4), (image_height // 4) * 64)\n",
        "    x = keras.layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n",
        "    x = keras.layers.Dense(64, activation=\"relu\", name=\"dense1\")(x)\n",
        "    x = keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "    # RNNs.\n",
        "    x = keras.layers.Bidirectional(\n",
        "        keras.layers.LSTM(128, return_sequences=True, dropout=0.25)\n",
        "    )(x)\n",
        "    x = keras.layers.Bidirectional(\n",
        "        keras.layers.LSTM(64, return_sequences=True, dropout=0.25)\n",
        "    )(x)\n",
        "\n",
        "    # +2 is to account for the two special tokens introduced by the CTC loss.\n",
        "    # The recommendation comes here: https://git.io/J0eXP.\n",
        "    x = keras.layers.Dense(\n",
        "        len(charList) + 2, activation=\"softmax\", name=\"dense2\"\n",
        "    )(x)\n",
        "\n",
        "    # Add CTC layer for calculating CTC loss at each step.\n",
        "    output = CTCLayer(name=\"ctc_loss\")(labels, x)\n",
        "\n",
        "    # Define the model.\n",
        "    model = keras.models.Model(\n",
        "        inputs=[input_img, labels], outputs=output, name=\"handwriting_recognizer\"\n",
        "    )\n",
        "    # Optimizer.\n",
        "    opt = keras.optimizers.Adam()\n",
        "    # Compile the model and return.\n",
        "    model.compile(optimizer=opt)\n",
        "    return model\n",
        "\n",
        "\n",
        "# Get the model.\n",
        "model = build_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "03AnD3wKhCq_",
        "outputId": "ee06b950-4b74-40a8-cba7-448948abc81f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"handwriting_recognizer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " image (InputLayer)             [(None, 128, 32, 1)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " Conv1 (Conv2D)                 (None, 128, 32, 32)  320         ['image[0][0]']                  \n",
            "                                                                                                  \n",
            " pool1 (MaxPooling2D)           (None, 64, 16, 32)   0           ['Conv1[0][0]']                  \n",
            "                                                                                                  \n",
            " Conv2 (Conv2D)                 (None, 64, 16, 64)   18496       ['pool1[0][0]']                  \n",
            "                                                                                                  \n",
            " pool2 (MaxPooling2D)           (None, 32, 8, 64)    0           ['Conv2[0][0]']                  \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 32, 512)      0           ['pool2[0][0]']                  \n",
            "                                                                                                  \n",
            " dense1 (Dense)                 (None, 32, 64)       32832       ['reshape[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 32, 64)       0           ['dense1[0][0]']                 \n",
            "                                                                                                  \n",
            " bidirectional_2 (Bidirectional  (None, 32, 256)     197632      ['dropout_1[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " bidirectional_3 (Bidirectional  (None, 32, 128)     164352      ['bidirectional_2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " label (InputLayer)             [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dense2 (Dense)                 (None, 32, 28)       3612        ['bidirectional_3[0][0]']        \n",
            "                                                                                                  \n",
            " ctc_loss (CTCLayer)            (None, 32, 28)       0           ['label[0][0]',                  \n",
            "                                                                  'dense2[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 417,244\n",
            "Trainable params: 417,244\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10  # To get good results this should be at least 50.\n",
        "\n",
        "model = build_model()\n",
        "prediction_model = keras.models.Model(\n",
        "    model.get_layer(name=\"image\").input, model.get_layer(name=\"dense2\").output\n",
        ")\n",
        "#edit_distance_callback = EditDistanceCallback(prediction_model)\n",
        "\n",
        "# Train the model.\n",
        "history = model.fit(\n",
        "    data_ds,\n",
        "    \n",
        "    epochs=epochs,\n",
        "    \n",
        ")"
      ],
      "metadata": {
        "id": "yUeabesUgajR",
        "outputId": "26099b66-f854-4547-df43-2350cf32c800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 970
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-8a9f59b497ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdata_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_fileqse2rnun.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0minput_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mlabel_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_length\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_fileqse2rnun.py\", line 15, in tf__call\n        loss = ag__.converted_call(ag__.ld(self).loss_fn, (ag__.ld(y_true), ag__.ld(y_pred), ag__.ld(input_length), ag__.ld(label_length)), None, fscope)\n\n    TypeError: Exception encountered when calling layer \"ctc_loss\" (type CTCLayer).\n    \n    in user code:\n    \n        File \"<ipython-input-16-8a99698d6d39>\", line 15, in call  *\n            loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n        File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 6619, in ctc_batch_cost\n            ctc_label_dense_to_sparse(y_true, label_length), tf.int32)\n        File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 6587, in ctc_label_dense_to_sparse\n            vals_sparse = tf.compat.v1.gather_nd(labels, indices)\n    \n        TypeError: Failed to convert elements of SparseTensor(indices=Tensor(\"DeserializeSparse:0\", shape=(None, 2), dtype=int64), values=Tensor(\"handwriting_recognizer/Cast:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"DeserializeSparse:2\", shape=(2,), dtype=int64)) to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes.\n    \n    \n    Call arguments received by layer \"ctc_loss\" (type CTCLayer):\n       y_true=<tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f480dc34d90>\n       y_pred=tf.Tensor(shape=(128, 32, 28), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model_3"
      ],
      "metadata": {
        "id": "_olz0nqLQaw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_history=model_3.fit(dataset_train,epochs=2, validation_data=dataset_test)"
      ],
      "metadata": {
        "id": "aAvh8CToQc5C",
        "outputId": "41aed76d-7d0b-4b7f-9f3a-ce925d4dd36a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "678/678 [==============================] - 97s 139ms/step - loss: 12.4228 - val_loss: 12.5318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qy11fIhRQc12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.predict(X_t[:30])"
      ],
      "metadata": {
        "id": "R6Bt2UJJUcL9",
        "outputId": "6595b754-9a8c-4ba2-a7b1-123c4a7af520",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 697ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-570.1915 , -571.743  , -571.17084, ..., -571.9455 ,\n",
              "         -572.91473, -566.13434],\n",
              "        [-570.1915 , -571.743  , -571.1709 , ..., -571.9455 ,\n",
              "         -572.91473, -566.13434],\n",
              "        [-568.80585, -570.63135, -569.8974 , ..., -570.82996,\n",
              "         -571.8575 , -565.0103 ],\n",
              "        ...,\n",
              "        [-570.19086, -571.7423 , -571.1702 , ..., -571.9449 ,\n",
              "         -572.9141 , -566.13367],\n",
              "        [-556.7652 , -558.8211 , -557.3126 , ..., -558.98224,\n",
              "         -559.92523, -553.7977 ],\n",
              "        [-544.6033 , -546.10535, -544.91187, ..., -546.74615,\n",
              "         -548.18164, -541.8459 ]],\n",
              "\n",
              "       [[-570.1915 , -571.743  , -571.17084, ..., -571.9455 ,\n",
              "         -572.91473, -566.13434],\n",
              "        [-570.1915 , -571.743  , -571.17084, ..., -571.9455 ,\n",
              "         -572.91473, -566.13434],\n",
              "        [-570.18494, -571.73627, -571.1645 , ..., -571.93933,\n",
              "         -572.90814, -566.12756],\n",
              "        ...,\n",
              "        [-570.1905 , -571.7418 , -571.16974, ..., -571.9445 ,\n",
              "         -572.91364, -566.13324],\n",
              "        [-558.9861 , -560.88336, -559.24695, ..., -561.05634,\n",
              "         -561.96606, -555.69855],\n",
              "        [-507.37985, -508.46603, -507.26733, ..., -508.55035,\n",
              "         -511.23837, -506.38733]],\n",
              "\n",
              "       [[-570.1915 , -571.743  , -571.17084, ..., -571.9455 ,\n",
              "         -572.91473, -566.13434],\n",
              "        [-570.1915 , -571.743  , -571.1709 , ..., -571.94556,\n",
              "         -572.91473, -566.13434],\n",
              "        [-570.18494, -571.73627, -571.1645 , ..., -571.93933,\n",
              "         -572.90814, -566.1276 ],\n",
              "        ...,\n",
              "        [-570.1916 , -571.743  , -571.1709 , ..., -571.94556,\n",
              "         -572.91473, -566.13434],\n",
              "        [-570.19147, -571.74286, -571.17084, ..., -571.9455 ,\n",
              "         -572.9147 , -566.1343 ],\n",
              "        [-563.4611 , -564.9581 , -564.59686, ..., -564.5002 ,\n",
              "         -566.13605, -559.8285 ]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-570.1915 , -571.743  , -571.17084, ..., -571.9455 ,\n",
              "         -572.91473, -566.13434],\n",
              "        [-570.1915 , -571.743  , -571.1709 , ..., -571.9455 ,\n",
              "         -572.91473, -566.13434],\n",
              "        [-570.18494, -571.73627, -571.1645 , ..., -571.93933,\n",
              "         -572.90814, -566.1276 ],\n",
              "        ...,\n",
              "        [-546.21466, -547.6986 , -546.16437, ..., -548.39166,\n",
              "         -549.21344, -543.9727 ],\n",
              "        [-523.3194 , -524.75037, -522.79175, ..., -525.9372 ,\n",
              "         -527.36383, -521.4805 ],\n",
              "        [-522.8189 , -523.6571 , -522.9274 , ..., -524.8531 ,\n",
              "         -526.4072 , -520.73334]],\n",
              "\n",
              "       [[-570.1915 , -571.743  , -571.17084, ..., -571.9455 ,\n",
              "         -572.91473, -566.13434],\n",
              "        [-570.1915 , -571.743  , -571.1709 , ..., -571.94556,\n",
              "         -572.91473, -566.13434],\n",
              "        [-570.18365, -571.73486, -571.16327, ..., -571.93805,\n",
              "         -572.9068 , -566.1262 ],\n",
              "        ...,\n",
              "        [-570.19147, -571.7429 , -571.1708 , ..., -571.9455 ,\n",
              "         -572.9146 , -566.1342 ],\n",
              "        [-570.1575 , -571.7058 , -571.1319 , ..., -571.9105 ,\n",
              "         -572.88055, -566.1014 ],\n",
              "        [-556.9556 , -558.42004, -557.3776 , ..., -558.68494,\n",
              "         -559.8081 , -553.55176]],\n",
              "\n",
              "       [[-570.1915 , -571.743  , -571.17084, ..., -571.9455 ,\n",
              "         -572.91473, -566.13434],\n",
              "        [-570.1915 , -571.743  , -571.1709 , ..., -571.9455 ,\n",
              "         -572.91473, -566.13434],\n",
              "        [-570.1783 , -571.72955, -571.15814, ..., -571.933  ,\n",
              "         -572.9015 , -566.1208 ],\n",
              "        ...,\n",
              "        [-567.44257, -568.84454, -568.0724 , ..., -569.23285,\n",
              "         -570.3    , -563.56964],\n",
              "        [-555.5229 , -557.6401 , -555.96075, ..., -557.5662 ,\n",
              "         -558.78326, -552.3266 ],\n",
              "        [-547.52155, -549.15125, -547.9247 , ..., -549.6841 ,\n",
              "         -551.1074 , -544.62964]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decode the vector"
      ],
      "metadata": {
        "id": "FPRodf3hy6BF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_codes(codes):\n",
        "    table = tf.lookup.StaticHashTable(\n",
        "        tf.lookup.KeyValueTensorInitializer(\n",
        "            np.arange(len(charList)),\n",
        "            charList,\n",
        "            key_dtype=tf.int32\n",
        "        ),\n",
        "        '',\n",
        "        name='id2char'\n",
        "    )\n",
        "    return table.lookup(codes)\n",
        "\n",
        "def greedy_decoder(logits):\n",
        "    # ctc beam search decoder\n",
        "    predicted_codes, _ = tf.nn.ctc_greedy_decoder(\n",
        "        # shape of tensor [max_time x batch_size x num_classes]\n",
        "        tf.transpose(logits, (1, 0, 2)),\n",
        "        [logits.shape[1]]*logits.shape[0]\n",
        "    )\n",
        "\n",
        "    # convert to int32\n",
        "    codes = tf.cast(predicted_codes[0], tf.int32)\n",
        "\n",
        "    # Decode the index of caracter\n",
        "    text = decode_codes(codes)\n",
        "\n",
        "    # Convert a SparseTensor to string\n",
        "    text = tf.sparse.to_dense(text).numpy().astype(str)\n",
        "\n",
        "    return list(map(lambda x: ''.join(x), text))\n",
        "\n",
        "\n",
        "l = greedy_decoder(model_3(X_t[:30]))\n",
        "\n",
        "list(zip(l, y_t[:30].numpy()))"
      ],
      "metadata": {
        "id": "poycif5Xxjk0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b94bd5c-73a8-4b3f-bc58-c58b3aa7f4f2"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('kxizif', b'a'),\n",
              " ('kif', b'the'),\n",
              " ('kxixif', b','),\n",
              " ('kxif', b'hand'),\n",
              " ('kxif', b'far'),\n",
              " ('kxif', b'I'),\n",
              " ('kxif', b'dissolution'),\n",
              " ('kif', b'and'),\n",
              " ('kxiz', b'them'),\n",
              " ('kif', b'however'),\n",
              " ('kif', b'realized'),\n",
              " ('kxif', b'in'),\n",
              " ('kif', b'blew'),\n",
              " ('kxif', b'days'),\n",
              " ('kxif', b'junior'),\n",
              " ('kxif', b'would'),\n",
              " ('kif', b'child'),\n",
              " ('kxif', b'namely'),\n",
              " ('kxif', b'These'),\n",
              " ('kxif', b'well'),\n",
              " ('kxif', b'You'),\n",
              " ('kxizif', b'me'),\n",
              " ('kxif', b'in'),\n",
              " ('kxif', b'to'),\n",
              " ('kif', b'man'),\n",
              " ('kxif', b'officers'),\n",
              " ('kxif', b'beginner'),\n",
              " ('kxif', b'the'),\n",
              " ('kif', b'establishment'),\n",
              " ('kxif', b'carrying')]"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_t.numpy()[:30]"
      ],
      "metadata": {
        "id": "MR5E-6x6Uvi_",
        "outputId": "39ff0713-13c6-4ece-d482-20a366c4d75e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-c32d55bb7817>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'SparseTensor' object has no attribute 'numpy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_t, y_t = next(iter(dataset_train))"
      ],
      "metadata": {
        "id": "tKXRHwYDUvXw"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j52f7zjxUvTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "Wl-T6thUQrNs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oR3oqvIaQsK_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}